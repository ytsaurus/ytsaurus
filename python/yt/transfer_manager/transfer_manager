#!/usr/bin/env python

import yt.transfer_manager.traceback_helpers as traceback_helpers
from yt.transfer_manager.flask_helpers import process_gzip
from yt.transfer_manager.logger import TaskIdLogger
from yt.transfer_manager.pattern_matching import match_copy_pattern
from yt.transfer_manager.message_queue import MessageReader, MessageWriter

from yt.tools.logging_server import LogRecordSocketReceiver
from yt.tools.yamr import Yamr, YamrError
from yt.tools.hadoop import Hive
from yt.tools.remote_copy_tools import Kiwi
from yt.tools.remote_copy_tools import \
    copy_yamr_to_yt_pull, \
    copy_yt_to_yamr_pull, \
    copy_yt_to_yamr_push, \
    copy_yt_to_kiwi, \
    copy_yt_to_yt, \
    copy_yt_to_yt_through_proxy, \
    copy_hive_to_yt

from yt.wrapper.client import Yt
from yt.wrapper.common import generate_uuid, get_value, update
import yt.logger as logger
import yt.wrapper as yt

from flask import Flask, request, jsonify, Response, make_response

import os
import sys
import json
import time
import prctl
import signal
import socket
import logging
import logging.handlers
import thread
import argparse
import traceback
import subprocess
import pwd
from copy import deepcopy
from datetime import datetime, timedelta
from collections import defaultdict
from subprocess32 import TimeoutExpired
from threading import RLock, Thread
from multiprocessing import Process, Queue

yt.config["read_retries"]["enable"] = True

class RequestFailed(yt.YtError):
    pass

class IncorrectTokenError(RequestFailed):
    pass

class SchedulingError(yt.YtError):
    pass

class SafeThread(Thread):
    def __init__(self, group=None, target=None, name=None, terminate=None, args=None, kwargs=None):
        self._parent_pid = os.getpid()

        if args is None:
            args = ()
        if kwargs is None:
            kwargs = {}

        def safe_run(*args, **kwargs):
            try:
                target(*args, **kwargs)
            except KeyboardInterrupt:
                thread.interrupt_main()
                time.sleep(0.5)
                os.kill(self._parent_pid, signal.SIGTERM)
            except:
                print >>sys.stderr, "Unknown exception"
                print >>sys.stderr, traceback.format_exc()
                logger.exception("Unknown exception")
                os.kill(self._parent_pid, signal.SIGINT)
                time.sleep(0.5)
                os.kill(self._parent_pid, signal.SIGTERM)

        super(SafeThread, self).__init__(group=group, target=safe_run, name=name, args=args, kwargs=kwargs)

SIGTERM_SENT = False
def sigterm_handler(signum, frame):
    global SIGTERM_SENT
    if not SIGTERM_SENT:
        SIGTERM_SENT = True
        os.killpg(0, signal.SIGINT)
        time.sleep(0.5)
        os.killpg(0, signal.SIGTERM)

    os._exit(1)

def log_yt_exception(logger, message=None):
    # Python2.7 has a bug in unpickling exception with non-trivial constructor.
    # To overcome it we convert exception to string before logging through socket handler.
    # https://bugs.python.org/issue1692335
    exc_type, exc_value, exc_traceback = sys.exc_info()
    exception_string = "\n".join(traceback.format_exception(exc_type, str(exc_value), exc_traceback))
    if message is not None:
        logger.error(message + "\n" + exception_string)
    else:
        logger.error(exception_string)

def filter_out_keys(dict, keys):
    result = deepcopy(dict)
    for key in keys:
        if key in result:
            del result[key]
    return result

def remove_unsigned(obj):
    def is_uint(num):
        return isinstance(num, long) and (num < -2 ** 63 or num >= 2 ** 63)

    if isinstance(obj, list):
        result = []
        for value in obj:
            new_value = remove_unsigned(value)
            if not is_uint(new_value):
                result.append(new_value)
        return result
    elif isinstance(obj, dict):
        result = {}
        for key, value in obj.iteritems():
            new_value = remove_unsigned(value)
            if not is_uint(new_value):
                result[key] = new_value
        return result
    else:
        return obj

def truncate_stderrs_attributes(error, limit):
    if hasattr(error, "attributes") and "stderrs" in error.attributes:
        if isinstance(error, yt.YtOperationFailedError):
            error.attributes["details"] = yt.format_operation_stderrs(error.attributes["stderrs"])[:limit]
        elif isinstance(error, YamrError):
            error.attributes["details"] = error.attributes["stderrs"][:limit]
        del error.attributes["stderrs"]
    if hasattr(error, "inner_errors"):
        for inner_error in error.inner_errors:
            truncate_stderrs_attributes(inner_error, limit)

def now():
    return str(datetime.utcnow().isoformat() + "Z")

class Task(object):
    # NB: destination table is missing if we copy to kiwi
    def __init__(self, source_cluster, source_table, destination_cluster, creation_time, id, state, user,
                 destination_table=None, source_cluster_token=None, token=None, destination_cluster_token=None, mr_user=None, error=None,
                 start_time=None, finish_time=None, copy_method=None, progress=None, backend_tag=None, kiwi_user=None, kwworm_options=None, pool=None, meta=None,
                 destination_compression_codec=None, destination_erasure_codec=None, destination_force_sort=None):
        self.source_cluster = source_cluster
        self.source_table = source_table
        self.source_cluster_token = get_value(source_cluster_token, token)
        self.destination_cluster = destination_cluster
        self.destination_table = destination_table
        self.destination_cluster_token = get_value(destination_cluster_token, token)

        self.creation_time = creation_time
        self.start_time = start_time
        self.finish_time = finish_time
        self.state = state
        self.id = id
        self.user = user
        self.mr_user = mr_user
        self.error = error
        self.token = token
        self.copy_method = copy_method
        self.progress = progress

        self.backend_tag = backend_tag
        self.pool = pool
        self.kiwi_user = kiwi_user
        self.kwworm_options = kwworm_options

        self.destination_compression_codec = destination_compression_codec
        self.destination_erasure_codec = destination_erasure_codec
        self.destination_force_sort = destination_force_sort

        # Special field to store meta-information for web-interface
        self.meta = meta

    def get_queue_id(self):
        return self.source_cluster, self.destination_cluster

    def get_source_client(self, clusters):
        if self.source_cluster not in clusters:
            raise yt.YtError("Unknown cluster " + self.source_cluster)
        client = deepcopy(clusters[self.source_cluster])
        if client._type == "yt":
            client.config["token"] = self.source_cluster_token
        if client._type == "yamr" and self.mr_user is not None:
            client.mr_user = self.mr_user
        return client

    def get_destination_client(self, clusters):
        if self.destination_cluster not in clusters:
            raise yt.YtError("Unknown cluster " + self.destination_cluster)
        client = deepcopy(clusters[self.destination_cluster])
        if client._type == "yt":
            client.config["token"] = self.destination_cluster_token
        if client._type == "yamr" and self.mr_user is not None:
            client.mr_user = self.mr_user
        return client

    def dict(self, hide_token=False, fields=None):
        result = self.__dict__.copy()
        if hide_token:
            for key in ["token", "source_cluster_token", "destination_cluster_token"]:
                del result[key]
        for key in result.keys():
            if result[key] is None or (fields is not None and key not in fields) or key.startswith("_"):
                del result[key]
        return result

    def copy(self):
        return Task(**self.__dict__)

class Application(object):
    ERROR_BUFFER_SIZE = 2 ** 16

    def __init__(self, config_path):
        self._daemon = Flask(__name__)

        self._config_path = config_path
        self._config = config = json.load(open(config_path))
        self._mutex = RLock()
        self._yt = Yt(**config["yt_backend_options"])

        self._load_config(config)
        self._path = config["path"]
        self._logging_port = self._config["port"] + 1

        self._yandex_yt_python_tools_version = self._get_yandex_yt_python_tools_version()

    def init_logger(self):
        # Replace current logger with socket logger.
        logger.LOGGER.handlers = [logging.handlers.SocketHandler('localhost', self._logging_port)]

    def start_processes(self):
        self._sleep_step = 0.5

        # Run logging process. It inherits current logging configuration.
        self._logging_process = Process(target=self._run_logging_server, name="LoggingThread")
        self._logging_process.daemon = True
        self._logging_process.start()

        self.init_logger()

        # Prepare auth node if it is missing
        self._auth_path = os.path.join(self._path, "auth")
        self._yt.create("map_node", self._auth_path, ignore_existing=True)

        # Run lock thread
        self._terminating = False
        self._lock_acquired = False
        self._lock_path = os.path.join(self._path, "lock")
        self._lock_timeout = 10.0
        self._yt.create("map_node", self._lock_path, ignore_existing=True)
        self._lock_thread = SafeThread(target=self._take_lock, name="LockThread")
        self._lock_thread.daemon = True
        self._lock_thread.start()

        # Run execution thread
        self._task_processes = {}
        self._execution_thread = SafeThread(target=self._execute_tasks, name="SchedulingThread")
        self._execution_thread.daemon = True
        self._execution_thread.start()

        # Add rules
        self._add_rule("/", 'main', methods=["GET"], depends_on_lock=False)
        self._add_rule("/tasks/", 'get_tasks', methods=["GET"])
        self._add_rule("/tasks/", 'add', methods=["POST"])
        self._add_rule("/tasks/<id>/", 'get_task', methods=["GET"])
        self._add_rule("/tasks/<id>/", 'delete_task', methods=["DELETE"])
        self._add_rule("/tasks/<id>/abort/", 'abort', methods=["POST"])
        self._add_rule("/tasks/<id>/restart/", 'restart', methods=["POST"])
        self._add_rule("/config/", 'config', methods=["GET"])
        self._add_rule("/ping/", 'ping', methods=["GET"])
        self._add_rule("/match/", 'match', methods=["POST"])

    def terminate(self):
        self._terminating = True
        self._lock_thread.join(self._sleep_step)
        self._execution_thread.join(self._sleep_step)

    def _add_rule(self, rule, endpoint, methods, depends_on_lock=True):
        methods.append("OPTIONS")
        self._daemon.add_url_rule(
            rule,
            endpoint,
            self._process_lock(
                process_gzip(
                    self._process_cors(
                        self._process_exception(
                            Application.__dict__[endpoint]
                        ),
                        methods)
                    ),
                depends_on_lock),
            methods=methods)

    def _process_lock(self, func, depends_on_lock):
        def decorator(*args, **kwargs):
            if depends_on_lock and not self._lock_acquired:
                return "Cannot take lock", 500
            return func(*args, **kwargs)
        return decorator

    def _process_cors(self, func, methods):
        def decorator(*args, **kwargs):
            if request.method == "OPTIONS":
                rsp = self._daemon.make_default_options_response()
                rsp.headers["Access-Control-Allow-Origin"] = "*"
                rsp.headers["Access-Control-Allow-Methods"] = ", ".join(methods)
                rsp.headers["Access-Control-Allow-Headers"] = ", ".join(["Authorization", "Origin", "Content-Type", "Accept"])
                rsp.headers["Access-Control-Max-Age"] = 3600
                return rsp
            else:
                rsp = make_response(func(self, *args, **kwargs))
                rsp.headers["Access-Control-Allow-Origin"] = "*"
                return rsp

        return decorator

    def _process_exception(self, func):
        def decorator(*args, **kwargs):
            try:
                return func(*args, **kwargs)
            except RequestFailed as error:
                log_yt_exception(logger)
                return json.dumps(error.simplify()), 400
            except Exception as error:
                logger.exception("Unknown error:")
                return json.dumps({"code": 1, "message": "Unknown error: " + str(error)}), 502

        return decorator

    def _take_lock(self):
        yt_client = deepcopy(self._yt)
        with yt_client.Transaction():
            while True:
                try:
                    yt_client.lock(self._lock_path)
                    break
                except yt.YtError as err:
                    if err.is_concurrent_transaction_lock_conflict():
                        logger.info("Failed to take lock")
                        time.sleep(self._lock_timeout)
                        continue
                    log_yt_exception(logger)
                    return

            logger.info("Lock acquired")

            # Loading tasks from cypress
            self._load_tasks(os.path.join(self._path, "tasks"))

            self._lock_acquired = True

            # Set attribute outside of transaction
            self._yt.set_attribute(self._path, "address", socket.getfqdn())

            # Sleep infinitely long
            while True:
                if self._terminating:
                    return
                time.sleep(self._sleep_step)


    def _load_config(self, config):
        self._configure_logging(config.get("logging", {}))

        self._clusters = {}
        for name, cluster_description in config["clusters"].iteritems():
            type = cluster_description["type"]
            options = cluster_description["options"]

            if type == "yt":
                if "config" not in options:
                    options["config"] = {}
                options["config"] = update(config["yt_client_config"], options["config"])
                self._clusters[name] = Yt(**options)
                self._clusters[name]._pools = cluster_description.get("pools", {})
                self._clusters[name]._version = cluster_description.get("version", 0)
            elif type == "yamr":
                self._clusters[name] = Yamr(**options)
            elif type == "kiwi":
                self._clusters[name] = Kiwi(**options)
            elif type == "hive":
                self._clusters[name] = Hive(**options)
            else:
                raise yt.YtError("Incorrect cluster type " + options["type"])

            self._clusters[name]._name = name
            self._clusters[name]._type = type
            self._clusters[name]._parameters = filter_out_keys(cluster_description, ["type", "options"])

        self._availability_graph = deepcopy(config["availability_graph"])

        for name in self._availability_graph:
            edges = {}
            for neighbour in self._availability_graph[name]:
                if isinstance(neighbour, dict):
                    edges[neighbour["name"]] = neighbour.get("options", {})
                else:
                    edges[neighbour] = {}
            self._availability_graph[name] = edges

        for name in self._availability_graph:
            if name not in self._clusters:
                raise yt.YtError("Incorrect availability graph, cluster {} is missing".format(name))
            for neighbour in self._availability_graph[name]:
                if neighbour not in self._clusters:
                    raise yt.YtError("Incorrect availability graph, cluster {} is missing".format(neighbour))

        self.kiwi_transmitter = None
        if "kiwi_transmitter" in config:
            name = config["kiwi_transmitter"]
            if name not in self._clusters:
                raise yt.YtError("Incorrect kiwi transmitter, clustter {} is missing".format(name))
            self.kiwi_transmitter = self._clusters[name]
            if self.kiwi_transmitter._type != "yt":
                raise yt.YtError("Kiwi transmitter must be YT cluster")


    def _configure_logging(self, logging_node):
        level = logging.__dict__[logging_node.get("level", "INFO")]

        if "filename" in logging_node:
            handler = logging.handlers.WatchedFileHandler(logging_node["filename"])
        else:
            handler = logging.StreamHandler()

        new_logger = logging.getLogger("Transfer manager")
        new_logger.propagate = False
        new_logger.setLevel(level)
        new_logger.handlers = [handler]
        new_logger.handlers[0].setFormatter(logger.BASIC_FORMATTER)
        logger.LOGGER = new_logger

        logging.getLogger('werkzeug').setLevel(level)
        logging.getLogger('werkzeug').addHandler(handler)

    def _run_logging_server(self):
        prctl.set_pdeathsig(signal.SIGINT)
        socket_reciever = LogRecordSocketReceiver(lambda record: logger.LOGGER.handle(record),
                                                  port=self._logging_port)
        socket_reciever.serve_until_stopped()

    def _load_tasks(self, tasks_path):
        logger.info("Loading tasks from cypress")

        self._tasks_path = tasks_path
        if not self._yt.exists(self._tasks_path):
            self._yt.create("map_node", self._tasks_path)

        # From id to task description
        self._tasks = {}

        # From ... to task ids
        self._running_tasks_queues = defaultdict(lambda: [])
        self._runned_during_heartbeat = set()
        self._last_scheduled_time = defaultdict(lambda: datetime(year=1970, month=1, day=1))

        # List of tasks sorted by creation time
        self._pending_tasks = []

        # Number of pending tasks per user
        self._pending_tasks_per_user = defaultdict(lambda: 0)

        for id, options in self._yt.get(tasks_path).iteritems():
            try:
                task = Task(**options)
            except Exception:
                logger.warning("Failed to load task " + id)
                continue

            active_client, passive_client = self._get_active_and_passive_clients(task)
            if active_client._type == "yt" and task.pool is None:
                logger.warning("Cannot load task %s: task has no pool", id)
                continue

            self._tasks[id] = task
            if task.state == "running":
                self._change_task_state(id, "pending")
            if task.state == "pending":
                self._append_pending_task(task)

        self._pending_tasks.sort(key=lambda id: self._tasks[id].creation_time)

        # Abort tasks operations (TM can fail but operations will go on)
        self._abort_failed_transfer_manager_operations()

        logger.info("Tasks load")

    def _append_pending_task(self, task):
        self._pending_tasks.append(task.id)
        self._pending_tasks_per_user[task.user] += 1

    def _change_task_state(self, id, new_state):
        with self._mutex:
            old_state = self._tasks[id].state
            self._tasks[id].state = new_state
            self._dump_task(id)
            logger.info("Task %s change state: %s -> %s", id, old_state, new_state)

    def _dump_task(self, id):
        with self._mutex:
            self._yt.set(os.path.join(self._tasks_path, id), remove_unsigned(self._tasks[id].dict()))

    def _create_pool(self, yt_client, destination_cluster_name):
        pool_name = "transfer_" + destination_cluster_name
        pool_path = "//sys/pools/transfer_manager/" + pool_name
        yt_client = deepcopy(yt_client)
        yt_client.config["token"] = self._yt.config["token"]
        try:
            if not yt_client.exists(pool_path):
                yt_client.create("map_node", pool_path, recursive=True, ignore_existing=True)
                yt_client.set(pool_path + "/@resource_limits", {"user_slots": 200})
                yt_client.set(pool_path + "/@mode", "fifo")
            while not yt_client.exists("//sys/scheduler/orchid/scheduler/pools/" + pool_name):
                time.sleep(0.5)
        except yt.YtError as err:
            raise yt.YtError("Transfer manager failed to create pool path: %s" % pool_path, inner_errors=[err])
        return pool_name

    # Return pair: active client, that run copy operation and passive client.
    def _get_active_and_passive_clients(self, task):
        source_client = task.get_source_client(self._clusters)
        destination_client = task.get_destination_client(self._clusters)

        if destination_client._type == "yamr":
            if source_client._type == "yt" and task.copy_method == "push":
                return source_client, destination_client
            return destination_client, source_client
        elif destination_client._type == "yt":
            return destination_client, source_client
        elif destination_client._type == "kiwi":
            return self.kiwi_transmitter, source_client
        else:
            raise yt.YtError("Unknown destination client type: %r", destination_client._type)

    def _initialize_pool(self, task):
        if task.pool is not None:
            return

        active_client, passive_client = self._get_active_and_passive_clients(task)
        if active_client._type != "yt":
            return

        name = passive_client._name
        if name in active_client._pools:
            pool = active_client._pools[name]
        else:
            pool = self._create_pool(active_client, name)
        task.pool = pool

    def _get_token(self, authorization_header):
        words = authorization_header.split()
        if len(words) != 2 or words[0].lower() != "oauth":
            return None
        return words[1]

    def _get_token_and_user(self, headers_):
        headers = {}
        for key, value in headers_.iteritems():
            headers[key] = value
        # Passing Host header causes infinite redirect on locke
        if "Host" in headers:
            del headers["Host"]

        token = self._get_token(headers.get("Authorization", ""))
        if "X-Forwarded-For" in headers:
            #headers["X-Forwarded-For"] += ", " + request.remote_addr
            # NB: it is not yet supported by proxy.
            pass
        else:
            headers["X-Forwarded-For"] = request.remote_addr
        if token == "undefined":
            user = "guest"
            token = ""
        else:
            user = self._yt.get_user_name(token, headers=headers)
            if not user:
                raise IncorrectTokenError("Authorization token is incorrect: " + token)
        return token, user

    @staticmethod
    def _get_yandex_yt_python_tools_version():
        if os.path.isfile("/etc/yandex_yt_python_tools/version"):
            return open("/etc/yandex_yt_python_tools/version").read().strip()
        return None

    def _check_permission(self, id, headers, action_name):
        _, user = self._get_token_and_user(headers)
        if self._tasks[id].user != user and \
           self._yt.check_permission(user, "administer", self._auth_path)["action"] != "allow":
            raise RequestFailed("{0} task is not permitted.".format(action_name))

    def _set_defaults(self, task):
        source_client = task.get_source_client(self._clusters)
        destination_client = task.get_destination_client(self._clusters)
        if task.mr_user is None and (source_client._type == "yamr" or destination_client._type == "yamr"):
            task.mr_user = self._config.get("default_mr_user")
        if task.kiwi_user is None and destination_client._type == "kiwi":
            task.kiwi_user = self._config.get("default_kiwi_user")
        if task.copy_method is None and source_client._type == "yt" and destination_client._type == "yamr":
            task.copy_method = "pull"
        if task.copy_method is None and source_client._type == "yt" and destination_client._type == "yt":
            task.copy_method = "proxy" if source_client._version != destination_client._version else "native"

    def _precheck(self, task, ignore_timeout=False, yamr_timeout=None, custom_logger=None):
        if custom_logger is None:
            custom_logger = logger

        # TODO(ignat): add timeout for yt
        custom_logger.info("Starting precheck")
        source_client = task.get_source_client(self._clusters)
        destination_client = task.get_destination_client(self._clusters)

        if task.copy_method not in [None, "pull", "push", "proxy", "native"]:
            raise yt.YtError("Incorrect copy method: " + str(task.copy_method))

        if task.source_cluster not in self._availability_graph or \
           task.destination_cluster not in self._availability_graph[task.source_cluster]:
            raise yt.YtError("Cluster {} not available from {}".format(task.destination_cluster, task.source_cluster))

        try:
            if yamr_timeout is not None:
                if source_client._type == "yamr":
                    source_client._light_command_timeout = yamr_timeout
                if destination_client._type == "yamr":
                    destination_client._light_command_timeout = yamr_timeout

            if source_client._type == "yamr" and source_client.is_empty(task.source_table) or \
               source_client._type == "yt" and (
                    not source_client.exists(task.source_table) or
                    source_client.get_attribute(task.source_table, "row_count") == 0):
                raise yt.YtError("Source table {} is empty".format(task.source_table))

            if source_client._type == "yt" and destination_client._type == "yamr":
                path = yt.TablePath(task.source_table, end_index=1, simplify=False, client=source_client)
                keys = list(source_client.read_table(path, format=yt.JsonFormat(), raw=False).next())
                if set(keys + ["subkey"]) != set(["key", "subkey", "value"]):
                    raise yt.YtError("Keys in the source table must be a subset of ('key', 'subkey', 'value')")

            if source_client._type == "yt" and destination_client._type == "yt":
                if task.copy_method not in ["proxy", "native"]:
                    raise yt.YtError("Incorrect copy method {0} for YT to YT copy task".format(task.copy_method))
                if task.copy_method == "native" and source_client._version != destination_client._version:
                    raise yt.YtError("Native copy method should not be specified for clusters with "
                                     "different YT versions")

            if destination_client._type == "yt":
                destination_dir = os.path.dirname(task.destination_table)
                # NB: copy operations usually create directories if it do not exits.
                #if not destination_client.exists(destination_dir):
                #    raise yt.YtError("Destination directory {} should exist".format(destination_dir))
                destination_user = destination_client.get_user_name(task.destination_cluster_token)
                if destination_user is None or destination_client.check_permission(destination_user, "write", destination_dir)["action"] != "allow":
                    raise yt.YtError("There is no permission to write to {}. Please log in.".format(task.destination_table))

            if destination_client._type == "kiwi" and self.kiwi_transmitter is None:
                raise yt.YtError("Transimission cluster for transfer to kiwi is not configured")

            if source_client._type == "hive" and "." not in task.source_table:
                raise yt.YtError("Incorrect source table for hive, it must have format {database_name}.{table_name}")
        except TimeoutExpired:
            custom_logger.info("Precheck timed out")
            if not ignore_timeout:
                raise
            return

        custom_logger.info("Precheck completed")

    def _can_run(self, task):
        if task.get_queue_id() in self._runned_during_heartbeat:
            return False
        if len(self._running_tasks_queues[task.get_queue_id()]) >= self._config["running_tasks_limit_per_direction"]:
            return False
        if datetime.now() - self._last_scheduled_time[task.get_queue_id()] < timedelta(seconds=self._config["scheduling_backoff"]):
            return False

        client, _ = self._get_active_and_passive_clients(task)
        if client._type == "yt":
            if task.pool is None:
                raise SchedulingError("Task has no pool")
            pool_path = "//sys/scheduler/orchid/scheduler/pools/" + task.pool

            try:
                #if not client.exists(pool_path):
                #    raise SchedulingError("Pool %s does not exist" % task.pool)

                # TODO(ignat): uncomment after fix of resource_limits in 0.17 (YT-2222).
                #pool_info = client.get("//sys/scheduler/orchid/scheduler/pools/" + task.pool)
                ## This usage ratio differ from scheduler usage ratio, because it is calculated due to resource limits of pool.
                #usage_ratio = 0.0
                #for resource, usage in pool_info["resource_usage"].iteritems():
                #    limit = pool_info["resource_limits"][resource]
                #    if limit == 0:
                #        usage_ratio = 1.0
                #    else:
                #        usage_ratio = max(usage_ratio, float(usage) / limit)
                #if usage_ratio > 0.95:
                #    logger.warning("Pool %s on cluster %s is almost full, can not schedule task %s", task.pool, client.config["proxy"]["url"], task.id)
                #    result = False
                #else:
                #    result = True

                #return result
                return True
            except yt.YtError as error:
                new_error = SchedulingError("Cannot check pool")
                new_error.inner_errors = [error]
                raise new_error

        if client._type == "yamr":
            def is_transfer_manager_copy_operation(op):
                return "read_from_yt" in op.get("additionalInfo", {}).get("application", "") \
                    and op.get("systemUser") == pwd.getpwuid(os.getuid())[0]
            transfer_manager_operations = filter(is_transfer_manager_copy_operation, client.get_operations())
            job_count = sum(op.get("jobsInfo", {}).get("States", {}).get("Jobs", {}).get("inProgress", 0)
                            for op in transfer_manager_operations)
            if job_count > self._config["running_jobs_limit_per_direction"]:
                return False

        return True

    def _execute_tasks(self):
        while True:
            if self._terminating:
                return

            if not self._lock_acquired:
                time.sleep(self._lock_timeout)
                continue

            logger.info("Processing tasks")

            with self._mutex:
                logger.info("Progress: %d running, %d pending tasks found", len(self._task_processes), len(self._pending_tasks))

                for id, (process, message_queue) in self._task_processes.items():
                    logger.info("Task %s running", id)
                    error = None
                    completed = False

                    process_is_alive = process.poll() is None

                    while not message_queue.empty():
                        message = None
                        try:
                            message = message_queue.get_nowait()
                        except Queue.Empty:
                            break

                        if message["type"] == "error":
                            error = message["error"]
                        elif message["type"] == "operation_started":
                            self._tasks[id].progress["operations"].append(message["operation"])
                            self._dump_task(id)
                        elif message["type"] == "completed":
                            completed = True
                        else:
                            assert False, "Incorrect message type: " + message["type"]


                    if not process_is_alive and not (process.aborted or error is not None or completed):
                        message = "Process died silently"
                        logger.warning(message)
                        error = {"message": message, "code": 1}

                    if process.aborted or error is not None or completed:
                        self._tasks[id].finish_time = now()
                        if process.aborted:
                            pass
                        elif error is not None:
                            self._tasks[id].error = error
                            self._change_task_state(id, "failed")
                        elif completed:
                            if process_is_alive:
                                logger.warning("Task completed, but process still alive!")
                            self._change_task_state(id, "completed")

                        self._dump_task(id)
                        self._running_tasks_queues[self._tasks[id].get_queue_id()].remove(id)
                        del self._task_processes[id]

                for id in self._pending_tasks:
                    try:
                        if not self._can_run(self._tasks[id]):
                            logger.info("Task %s pending", id)
                            continue
                    except SchedulingError as error:
                        self._tasks[id].error = error.simplify()
                        self._change_task_state(id, "failed")
                        continue

                    queue_id = self._tasks[id].get_queue_id()
                    self._last_scheduled_time[queue_id] = datetime.now()
                    self._running_tasks_queues[queue_id].append(id)
                    self._runned_during_heartbeat.add(queue_id)
                    self._pending_tasks_per_user[self._tasks[id].user] -= 1

                    self._tasks[id].start_time = now()
                    self._tasks[id].progress = {"operations": []}
                    self._change_task_state(id, "running")

                    task_process = subprocess.Popen(["./transfer_manager", "--execute-task", "--config", self._config_path],
                                                    stdout=subprocess.PIPE, stdin=subprocess.PIPE,
                                                    preexec_fn=lambda: prctl.set_pdeathsig(signal.SIGINT))
                    task_process.stdin.write(json.dumps(self._tasks[id].dict()))
                    task_process.stdin.close()
                    task_process.aborted = False
                    queue = MessageReader(task_process.stdout)
                    self._task_processes[id] = (task_process, queue)

                self._pending_tasks = filter(lambda id: self._tasks[id].state == "pending", self._pending_tasks)
                self._runned_during_heartbeat.clear()

            time.sleep(self._sleep_step)

    def execute_task(self, task, message_queue):
        logger.LOGGER = TaskIdLogger(task.id)

        logger.info("Start executing task")
        try:
            self._precheck(task)

            title = "Supervised by transfer task " + task.id
            task_spec = {
                "title": title,
                "transfer_manager": {
                    "task_id": task.id,
                    "backend_tag": task.backend_tag
                },
                "pool": task.pool
            }

            source_client = task.get_source_client(self._clusters)
            destination_client = task.get_destination_client(self._clusters)
            parameters = self._availability_graph[task.source_cluster][task.destination_cluster]

            # Calculate fastbone
            fastbone = source_client._parameters.get("fastbone", False) and destination_client._parameters.get("fastbone", False)
            fastbone = parameters.get("fastbone", fastbone)

            if source_client._type == "yt" and destination_client._type == "yt":
                logger.info("Running YT -> YT remote copy operation")
                if task.copy_method == "proxy":
                    copy_yt_to_yt_through_proxy(
                        source_client,
                        destination_client,
                        task.source_table,
                        task.destination_table,
                        fastbone=fastbone,
                        spec_template=task_spec,
                        message_queue=message_queue)
                else:  # native
                    network_name = "fastbone" if fastbone else "default"
                    network_name = parameters.get("network_name", network_name)
                    copy_yt_to_yt(
                        source_client,
                        destination_client,
                        task.source_table,
                        task.destination_table,
                        network_name=network_name,
                        spec_template=task_spec,
                        message_queue=message_queue)
            elif source_client._type == "yt" and destination_client._type == "yamr":
                logger.info("Running YT -> YAMR remote copy")
                if task.copy_method == "push":
                    copy_yt_to_yamr_push(
                        source_client,
                        destination_client,
                        task.source_table,
                        task.destination_table,
                        fastbone=fastbone,
                        spec_template=task_spec,
                        message_queue=message_queue)
                else:
                    copy_yt_to_yamr_pull(
                        source_client,
                        destination_client,
                        task.source_table,
                        task.destination_table,
                        fastbone=fastbone,
                        force_sort=task.destination_force_sort,
                        message_queue=message_queue)
            elif source_client._type == "yamr" and destination_client._type == "yt":
                logger.info("Running YAMR -> YT remote copy")
                copy_yamr_to_yt_pull(
                    source_client,
                    destination_client,
                    task.source_table,
                    task.destination_table,
                    fastbone=fastbone,
                    compression_codec=task.destination_compression_codec,
                    erasure_codec=task.destination_erasure_codec,
                    force_sort=task.destination_force_sort,
                    spec_template=task_spec,
                    message_queue=message_queue)
            elif source_client._type == "yamr" and destination_client._type == "yamr":
                destination_client.remote_copy(
                    source_client.server,
                    task.source_table,
                    task.destination_table,
                    fastbone=fastbone)
            elif source_client._type == "yt" and destination_client._type == "kiwi":
                dc_name = source_client._parameters.get("dc_name")
                if dc_name is not None:
                    task_spec["scheduling_tag"] = dc_name
                copy_yt_to_kiwi(
                    source_client,
                    destination_client,
                    self.kiwi_transmitter,
                    task.source_table,
                    fastbone=fastbone,
                    kiwi_user=task.kiwi_user,
                    kwworm_options=task.kwworm_options,
                    spec_template=task_spec,
                    message_queue=message_queue)
            elif source_client._type == "hive" and destination_client._type == "yt":
                copy_hive_to_yt(
                    source_client,
                    destination_client,
                    task.source_table,
                    task.destination_table,
                    spec_template=task_spec,
                    message_queue=message_queue)
            else:
                raise Exception("Incorrect cluster types: {} source and {} destination".format(
                                source_client._type,
                                destination_client._type))
            logger.info("Task completed")

            message_queue.put({"type": "completed"})
        except KeyboardInterrupt:
            pass
        except yt.YtError as error:
            try:
                truncate_stderrs_attributes(error, self._config["error_details_length_limit"])
            except Exception:
                logger.exception("Task failed with error:")
                raise
            log_yt_exception(logger, "Task {} failed with error:".format(task.id))
            message_queue.put({
                "type": "error",
                "error": error.simplify()
            })
        except Exception as error:
            logger.exception("Task failed with error:")
            message_queue.put({
                "type": "error",
                "error": {
                    "message": str(error),
                    "code": 1,
                    "attributes": {
                        "details": (traceback_helpers.format_exc() if self._config["enable_detailed_traceback"] else traceback.format_exc())
                    }
                }
            })

    def _get_task_description(self, task):
        task_description = task.dict(hide_token=True)
        queue_index = 1
        with self._mutex:
            for id in self._pending_tasks:
                if id == task.id:
                    task_description["queue_index"] = queue_index
                if self._tasks[id].get_queue_id() == task.get_queue_id():
                    queue_index += 1
        return task_description

    def _abort_failed_transfer_manager_operations(self):
        for task_id, task in self._tasks.iteritems():
            if not task.progress or "operations" not in task.progress:
                continue
            for operation in task.progress["operations"]:
                cluster_name, operation_id = operation["cluster_name"], operation["id"]
                if self._clusters[cluster_name]._type != "yt":
                    logger.warning("Transfer manager does not support progress for non-YT cluster, "
                                   "but it unexpectedly found for %s cluster." % self._clusters[cluster_name]._type)
                    continue
                try:
                    if not self._yt.exists("//sys/operations/%s" % operation_id) or \
                           self._yt.get_operation_state(operation_id).is_finished():
                        continue
                    self._clusters[cluster_name].abort_operation(operation_id)
                    logger.info("Aborted outdated operation {} of task {}".format(operation_id, task_id))
                except yt.YtError:
                    log_yt_exception(logger, "Failed abort operation {} of task {}".format(operation_id, task_id))

    # Public interface
    def run(self, *args, **kwargs):
        self._daemon.run(*args, **kwargs)


    # Url handlers
    def main(self):
        return "This is YT transfer manager"

    def _create_task(self, params, token, user, dry_run, make_precheck):
        id = generate_uuid()
        logger.info("Adding task %s with id %s", json.dumps(params), id)

        # Move this check to precheck function
        required_parameters = set(["source_cluster", "source_table", "destination_cluster"])
        if not set(params) >= required_parameters:
            raise RequestFailed("All required parameters ({}) must be presented".format(", ".join(required_parameters)))
        if "destination_table" not in params:
            params["destination_table"] = None
        if "backend_tag" not in params:
            params["backend_tag"] = self._config.get("backend_tag")

        try:
            task = Task(id=id, creation_time=now(), user=user, token=token, state="pending", **params)
        except TypeError as error:
            raise RequestFailed("Cannot create task", inner_errors=[yt.YtError(error.message)])

        if len(self._pending_tasks) > self._config["pending_tasks_limit"]:
            raise RequestFailed("Too many pending tasks (>{0})".format(len(self._pending_tasks)))

        if self._pending_tasks_per_user[task.user] > self._config["pending_tasks_limit_per_user"]:
            raise RequestFailed("Too many pending tasks per user (>{0})".format(self._pending_tasks_per_user[task.user]))

        self._set_defaults(task)
        if make_precheck:
            try:
                self._precheck(task, ignore_timeout=True, yamr_timeout=5.0, custom_logger=TaskIdLogger(task.id))
            except yt.YtError as error:
                raise RequestFailed("Precheck of task {} failed".format(task.id), inner_errors=[error]), None, sys.exc_info()[2]

        if not dry_run:
            self._initialize_pool(task)
            self._yt.set(os.path.join(self._tasks_path, task.id), task.dict())
            with self._mutex:
                self._tasks[task.id] = task
                self._append_pending_task(task)
            logger.info("Task %s added", task.id)

        return task.id

    def add(self):
        try:
            params = json.loads(request.data)
        except ValueError as error:
            raise RequestFailed("Cannot parse JSON from body '{}'".format(request.data), inner_errors=[yt.YtError(error.message)])

        token, user = self._get_token_and_user(request.headers)
        dry_run = request.args.get("dry_run", False)

        if isinstance(params, list):
            ids = []
            for task_params in params:
                ids.append(self._create_task(params=task_params, token=token, user=user, dry_run=dry_run, make_precheck=False))
            return ids
        else:
            return self._create_task(params=params, token=token, user=user, dry_run=dry_run, make_precheck=True)

    def abort(self, id):
        if id not in self._tasks:
            raise RequestFailed("Unknown task " + id)

        logger.info("Aboring task %s", id)

        with self._mutex:
            self._check_permission(id, request.headers, "Aborting")

            if id in self._task_processes:
                process, _ = self._task_processes[id]
                process.aborted = True

                try:
                    os.kill(process.pid, signal.SIGINT)
                except OSError:
                    pass
                time.sleep(0.5)
                if process.poll() is None:
                    try:
                        os.kill(process.pid, signal.SIGTERM)
                    except OSError:
                        pass

            if id in self._pending_tasks:
                self._pending_tasks_per_user[self._tasks[id].user] -= 1
                self._pending_tasks.remove(id)

            if self._tasks[id].state not in ["aborted", "completed", "failed"]:
                self._change_task_state(id, "aborted")

        return ""

    def restart(self, id):
        if id not in self._tasks:
            raise RequestFailed("Unknown task " + id)

        logger.info("Restarting task %s", id)

        with self._mutex:
            self._check_permission(id, request.headers, "Restarting")
            if self._tasks[id].state not in ["completed", "aborted", "failed"]:
                raise RequestFailed("Cannot restart task in state " + self._tasks[id].state)

            self._tasks[id].state = "pending"
            self._tasks[id].creation_time = now()
            self._tasks[id].finish_time = None
            self._tasks[id].progress = None
            self._tasks[id].error = None
            self._dump_task(id)
            self._pending_tasks.append(id)

        return ""

    def get_task(self, id):
        if id not in self._tasks:
            return "Unknown task " + id, 400

        tasks = {}
        with self._mutex:
            pending_tasks = deepcopy(self._pending_tasks)
            tasks[id] = deepcopy(self._tasks[id])

        for task_id in pending_tasks:
            tasks[task_id] = self._tasks[task_id]

        task = tasks[id]
        task_description = task.dict(hide_token=True)
        queue_index = 1
        for task_id in pending_tasks:
            if task_id == id:
                task_description["queue_index"] = queue_index
                break
            if tasks[task_id].get_queue_id() == task.get_queue_id():
                queue_index += 1

        return jsonify(**task_description)

    def delete_task(self, id):
        if id not in self._tasks:
            return "Unknown task " + id, 400

        self._check_permission(id, request.headers, "Deleting")

        with self._mutex:
            if self._tasks[id].state not in ["completed", "aborted", "failed"]:
                raise RequestFailed("Cannot delete running task " + self._tasks[id].state)
            self._yt.remove(os.path.join(self._tasks_path, id), recursive=True)
            del self._tasks[id]

        return ""

    def get_tasks(self):
        with self._mutex:
            # NB: deepcopy is too slow, then we use two-level shallow copy.
            tasks = dict([(id, task.copy()) for id, task in self._tasks.iteritems()])
            # NB: Number of pending tasks is rather small, so we can use deepcopy here.
            pending_tasks = deepcopy(self._pending_tasks)

        user = request.args.get("user")
        fields = request.args.getlist("fields[]")
        if not fields:
            fields = None
        if user is not None:
            tasks = [task.user == user for task in tasks]

        tasks_queue_indexes = {}
        queue_sizes = defaultdict(lambda: 0)
        for id in pending_tasks:
            queue_id = tasks[id].get_queue_id()
            queue_sizes[queue_id] += 1
            tasks_queue_indexes[id] = queue_sizes[queue_id]

        tasks_descriptions = []
        for id, task in tasks.iteritems():
            description = task.dict(hide_token=True, fields=fields)
            if id in tasks_queue_indexes:
                description["queue_index"] = tasks_queue_indexes[id]

            try:
                json.dumps(description)
            except json.UnicodeDecodeError:
                logger.warning("Cannot decode in JSON struct '%s'", repr(description))
                continue

            tasks_descriptions.append(description)

        return Response(json.dumps(tasks_descriptions), mimetype='application/json')

    def config(self):
        return jsonify(self._config)

    def ping(self):
        return "OK", 200

    def match(self):
        params = json.loads(request.data)
        source_pattern = params["source_pattern"]
        destination_pattern = params["destination_pattern"]
        source_cluster = params["source_cluster"]

        if source_cluster not in self._clusters:
            raise yt.YtError("Unknown cluster " + source_cluster)
        client = deepcopy(self._clusters[source_cluster])

        matchings = match_copy_pattern(client, source_pattern, destination_pattern)
        return Response(json.dumps(matchings), mimetype='application/json')


def main():
    signal.signal(signal.SIGTERM, sigterm_handler)

    parser = argparse.ArgumentParser(description="Transfer manager.")
    parser.add_argument("--execute-task", action="store_true", default=False)
    parser.add_argument("--config", required=True)
    args = parser.parse_args()

    if args.execute_task:
        app = Application(args.config)
        app.init_logger()
        task = Task(**json.loads(sys.stdin.read().strip()))
        message_queue = MessageWriter(sys.stdout)
        app.execute_task(task, message_queue)
    else:
        app = Application(args.config)
        app.start_processes()
        app.run(host=app._config.get("host", "::"), port=app._config["port"], use_reloader=False, threaded=True)
        app.terminate()

if __name__ == "__main__":
    main()
