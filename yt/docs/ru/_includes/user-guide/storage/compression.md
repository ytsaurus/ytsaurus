# Сжатие

В данном разделе описаны алгоритмы сжатия, поддерживаемые {{product-name}}.

В {{product-name}} пользовательские данные по умолчанию хранятся и передаются в сжатом виде.

Система самостоятельно производит сжатие:
1. При записи в таблицу или файл данные разбиваются на части — [чанки](../../../user-guide/storage/chunks.md).
2. Каждый чанк сжимается алгоритмом, указанным для данного файла или таблицы, и записывается на диск.
3. Для передачи по сети данные считываются с диска уже в сжатом виде.

## Просмотр алгоритма сжатия { #get_compression }

В системе {{product-name}} могут быть сжаты чанки, файлы и таблицы.

Алгоритм сжатия указан в атрибуте `compression_codec`:

- Для чанков атрибут `compression_codec` задает алгоритм сжатия всех блоков чанка. Разные чанки внутри файла или таблицы могут быть сжаты с помощью разных алгоритмов.
- Для таблиц и файлов `compression_codec` определяет алгоритм сжатия по умолчанию. Он будет использован, если для отдельных чанков файла или таблицы алгоритм не указан. Значение `compression_codec` по умолчанию: для таблиц — `lz4`, для файлов — `none` (без сжатия).

Степень сжатия данных указана в атрибутах `compressed_data_size` и `uncompressed_data_size` чанка, таблицы или файла:

- Для чанков атрибут `uncompressed_data_size` показывает размер чанка до сжатия, атрибут `compressed_data_size` — размер чанка после сжатия.
- Для таблиц и файлов атрибут `uncompressed_data_size` показывает суммарный размер несжатых данных всех чанков объекта, атрибут `compressed_data_size` — размер сжатых данных.

Статистика по алгоритмам сжатия, используемых в чанках таблицы, содержится в атрибуте `compression_statistics` таблицы.

## Изменение алгоритма сжатия { #set_compression }

Чтобы изменить алгоритм сжатия существующей статической таблицы, установите новое значение атрибута `compression_codec`. Затем запустите команду `merge`, чтобы выполнить повторное сжатие чанков.

CLI

```bash
yt set //path/to/table/@compression_codec zstd_3
yt merge --src //path/to/table --dst //path/to/table --spec '{force_transform = %true}'
```

Чтобы изменить алгоритм сжатия [динамической таблицы](../../../user-guide/dynamic-tables/overview.md), установите новое значение атрибута `compression_codec`. Затем выполните `remount-table`. Старые чанки со временем будут повторно сжаты в процессе компактификации. Скорость сжатия зависит от объема таблицы, скорости записи, настроек фоновой компактификации.

CLI

```bash
yt set //path/to/table/@compression_codec zstd_3
yt remount-table //path/to/table
```

Если в таблицу идёт постоянная запись, как правило, нет необходимости в [форсированном сжатии](../../../user-guide/dynamic-tables/compaction.md#forced_compaction). Если требуется форсировать сжатие, используйте `forced compaction`.

## Поддерживаемые алгоритмы сжатия { #compression_codecs }

| Алгоритм сжатия        | Описание         | Скорость сжатия/распаковки  | Степень сжатия  |
| ---------------------- | ---------------- | --------------------------- | --------------- |
| `none`                 | Без сжатия.                                 | -                                | -                                |
| `snappy`               | Подробнее об алгоритме [snappy](https://google.github.io/snappy/). | +++ | +- |
| `zlib_[1..9]`          | Система {{product-name}} поддерживает все 9 уровней. Чем больше уровень, тем сильнее и тем медленнее сжимаются данные. Подробнее об алгоритме [zlib](https://zlib.net). | ++ | ++ |
| `lz4`                  | Алгоритм сжатия по умолчанию для таблиц. Подробнее об алгоритме [lz4](https://lz4.github.io/lz4/). | +++ | + |
| `lz4_high_compression` | Алгоритм `lz4` c включенной опцией `high_compression`. Сжимает эффективнее, но существенно медленнее. По степени сжатия уступает `zlib`. | ++ | ++- |
| `zstd_[1..21]`         | Подробнее об алгоритме [zstd](https://github.com/facebook/zstd). | ++ | ++ |
| `brotli_[1..11]`       | Данный алгоритм рекомендуется к использованию для данных, которые не являются временными. Рекомендуется использовать уровни 3, 5 и 8 — они имеют лучшее соотношение объема и скорости. Подробнее об алгоритме [brotli](https://github.com/google/brotli). | ++ | +++ |
| `lzma_[0..9]`          | Подробнее об алгоритме [lzma](https://www.7-zip.org). | + | +++ |
| `bzip2_[1..9]`          | Подробнее об алгоритме [bzip2](http://www.bzip.org). | ++ | ++ |

## Рекомендации { #best_practice }

- Для файлов, которые используются в операции в виде [симлинков](../../../user-guide/storage/links.md) на чанки, сжатие чаще всего не применяется.
- `lz4` часто используется для актуальных данных. Алгоритм обеспечивает высокую скорость сжатия и распаковки при приемлемом коэффициенте сжатия.
- Когда необходимо максимальное сжатие, а длительное время работы является приемлемым, часто используется `brotli_8`.
- Для операций, состоящих из малого количества джобов, например, `final sort` или `sorted merge`, рекомендуется добавить отдельную стадию обработки — сжатие данных в операции merge с большим числом джобов.

{% note warning "Внимание" %}

Хотя алгоритмы с сильным сжатием (`zlib`, `zstd`, `brotli`) позволяют экономить место на диске, их скорость сжатия на порядок ниже, чем у алгоритма по умолчанию (`lz4`). Использование алгоритмов с сильным сжатием может привести к значительному росту времени выполнения операций. Рекомендуется использовать их только для таблиц, которые занимают много места, но редко меняются.

{% endnote %}

## Сравнение алгоритмов сжатия { #benchmarks }

Способ, описанный ниже, работает только для статических таблиц.

Чтобы определить, какой алгоритм лучше подойдет для определенной таблицы, запустите `yt run-compression-benchmarks TABLE`. Из таблицы будет взят сэмпл, по умолчанию равный 1 ГБ. Он будет сжат всеми алгоритмами.

После завершения операции вы увидите `codec/cpu/encode`, `codec/cpu/decode` и `compression_ratio` для каждого алгоритма. Подробнее смотрите в разделе [Статистики джобов](../../../user-guide/problems/jobstatistics.md#system_stats).

Для алгоритмов с несколькими уровнями сжатия по умолчанию используются минимальный, средний и максимальный уровни.
Чтобы получить результаты по всем уровням, используйте опцию `--all-codecs`.

CLI
```bash
yt run-compression-benchmarks //home/dev/tutorial/compression_benchmark_data
```
```bash
[
    {
        "codec": "brotli_1",
        "codec/cpu/decode": 2103,
        "codec/cpu/encode": 2123,
        "compression_ratio": 0.10099302059669339
    },
    ...
    {
        "codec": "brotli_11",
        "codec/cpu/decode": "Not launched",
        "codec/cpu/encode": "Timed out", # сжатие не успело завершиться за стандартный --time-limit-sec (200)
        "compression_ratio": "Timed out"
    },
    ...
    {
        "codec": "none",
        "codec/cpu/decode": 0,
        "codec/cpu/encode": 247,
        "compression_ratio": 1.0
    },
    ...
    {
        "codec": "zstd_11",
        "codec/cpu/decode": 713,
        "codec/cpu/encode": 15283,
        "compression_ratio": 0.07451278201257201
    },
    ...
]
```
