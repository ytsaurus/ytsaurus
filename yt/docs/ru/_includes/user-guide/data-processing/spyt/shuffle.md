# Использование {{product-name}} Shuffle сервиса

{% note info %}

Сервис доступен начиная с версии SPYT 2.7.3.

{% endnote %}

{{product-name}} Shuffle сервис нужен для хранения промежуточных данных между стадиями вычислений. В отличие от стандартного Spark Shuffle сервиса, который хранит промежуточные данные в оперативной памяти и во временных директориях на диске, {{product-name}} Shuffle сервис хранит их в чанках {{product-name}}. Это позволяет повысить устойчивость к падениям стадий распределенных Spark вычислений.

## Включение { #enabling }

При использовании режима [прямого запуска задач в {{product-name}}](../../../../user-guide/data-processing/spyt/launch.md#submit) необходимо выставить conf параметр `spark.ytsaurus.shuffle.enabled` в `true`.

При использовании [внутреннего standalone Spark кластера внутри Vanilla операции](../../../../user-guide/data-processing/spyt/launch.md#standalone) необходимо добавить опцию `--enable-ytsaurus-shuffle` для команды `spark-launch-yt`.

## Принцип работы

Spark пишет данные в {{product-name}} Shuffle сервис под транзакцией. Жизненный цикл этой транзакции контролируется драйвером, который её периодически пингует. Транзакция запускается в момент регистрации нового shuffle, каждый shuffle записывается под отдельной транзакцией. После завершения работы (как успешного, так и неуспешного) с экземляром shuffle транзакция откатывается, что приводит к удалению всех чанков, которые были под ней записаны. В случае ошибок на драйвере и его аварийного завершения транзакция также откатывается по истечении таймаута. Таймаут конфигурируется параметром `spark.ytsaurus.shuffle.transaction.timeout`.

Данные, записанные через shuffle сервис, не доступны для чтения через API {{product-name}}.

## Рекомендации по применению { #recommendations }

{{product-name}} Shuffle сервис рекомендуется использовать в следующих случаях:

- Для сложных расчётов, содержащих много промежуточных стадий (Stage). Например, при соединении (join) нескольких крупных таблиц, размер каждой из которых превышает 10M. Если помимо сложных расчётов на кластере выполняются также простые вычисления (например простые агрегации или соединение большой таблицы с маленькой), Shuffle сервис всё равно рекомендуется включать.

- При использовании режима [прямого запуска задач в {{product-name}}](../../../../user-guide/data-processing/spyt/launch.md#submit). Shuffle сервис записывает промежуточные данные в чанки {{product-name}}, которые не теряются в случае падения или вытеснения Spark экзекьюторов. Это позволяет не пересчитывать заново этапы, которые были уже посчитаны, но хранились на потерянных экзекьюторах.

## Конфигурационные параметры { #configuration }

Все параметры, относящиеся к конфигурации работы с {{product-name}} Shuffle сервисом, описаны [на странице конфигурационных параметров](../../../../user-guide/data-processing/spyt/thesaurus/configuration.md#shuffle).
