# Прямой сабмит SPYT

В данном разделе приводится верхнеуровневое описание прямого сабмита в {{product-name}} и его компонент.

Запуск Spark приложений в режиме прямого сабмита описан в отдельном [разделе](../../../../../user-guide/data-processing/spyt/launch.md#submit).

## Принцип работы { #explanation }

Ключевая идея заключается в том, что Spark делегирует управление ресурсами планировщику {{product-name}}.

### Выделение ресурсов для драйвера { #driver-resources }

- **Cluster mode (Кластерный режим)**: Драйвер также запускается в отдельной Vanilla-операции внутри кластера {{product-name}}. В этом режиме жизненный цикл драйвера (включая логирование, мониторинг и перезапуск при сбоях) полностью контролируется YTsaurus. Подходит для production задач.
- **Client mode (Клиентский режим)**: Драйвер запускается на клиентском хосте — например, на локальной машине разработчика или в Jupyter-ноутбуке. Этот режим удобен для отладки и интерактивной работы, так как обеспечивает прямой доступ к логам и состоянию драйвера.

  {% note warning "Внимание" %}

  В клиентском режиме должен быть обеспечен сетевой доступ между экзекьюторами и драйвером.

  {% endnote %}

### Выделение ресурсов для экзекьюторов { #executor-resources }

В данном режиме планировщик выделяют ресурсы экзекьюторам напрямую в рамках отдельной Vanilla операции на кластере {{product-name}}. Джоба в составе операции соответствует одному экзекьютору Spark. Спецификация экзекьюторов (количество CPU, объем памяти, тип диска и т.п.) описаны в разделе Task в спецификации операции. Возможно описание разных профилей ресурсов для экзекьюторов Spark для задач с неоднородной нагрузкой в течение жизенного цикла.

![](../../../../../../images/spyt-direct-submit-operation-concept.png){ .center }

### Конфигурирование {{product-name}} операции  { #operation-config }

Помимо стандартных параметров Spark для драйвера и экзекьюторов дополнительно можно конфигурировать операции и таски через соответствующие conf параметры `spark.ytsaurus.{driver|executor}.{operation|task}.parameters`. Например, `--conf spark.ytsaurus.executor.operation.shutdown.delay=10000`.

### Преимущества подхода { #advantages }

- **Эффективное использование ресурсов** — выделение по требованию, минимум простоя.
- **Простое управление** — единый уровень контроля вместо дублирования (YTsaurus + Standalone).
- **Гибкость** — работа без потерь при низкой загрузке.
- **Быстрый старт задач** — нет нужды предварительно поднимать кластер.
- **Лёгкая миграция** — совместимость с другими кластерами (включая Hadoop) за счёт стандартного SparkAPI.

## Выполнение локальных файлов { #submit-local }

Начиная с версии SPYT 2.4.0 при запуске задач напрямую в {{product-name}} можно указывать локальные файлы в качестве исполняемых модулей и зависимостей без их предварительной загрузки на Кипарис. В этом случае локальные файлы будут предварительно загружены в файловый кеш на Кипарисе и затем будут оттуда использованы в приложении. При повторном запуске будут использоваться уже закешированные файлы. Пример команды `spark-submit` для данного способа приведен ниже:

```bash
spark-submit --master ytsaurus://<cluster name> \
             --deploy-mode cluster \
             --num-executors 5 \
             --executor-cores 4 \
             --py-files ~/path/to/my/dependencies.py \
             ~/path/to/my/script.py
```
