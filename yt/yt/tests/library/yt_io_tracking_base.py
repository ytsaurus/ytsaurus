from yt_env_setup import YTEnvSetup

from yt_commands import update_nodes_dynamic_config, wait

from yt_helpers import read_structured_log, write_log_barrier


class TestIOTrackingBase(YTEnvSetup):
    ENABLE_MULTIDAEMON = False  # Check structured logs.

    def setup_method(self, method):
        super(TestIOTrackingBase, self).setup_method(method)
        update_nodes_dynamic_config({
            "io_tracker": {
                "enable": True,
                "enable_raw": True,
                "enable_path": True,
                "period_quant": 10,
                "aggregation_period": 5000,
                "path_aggregate_tags": ["direction@", "account@", "user@"]
            }
        })

    def _get_logs_base_path(self, cluster_index=0):
        if self.NUM_REMOTE_CLUSTERS == 0:
            return self.path_to_run
        return self.path_to_run + "/" + self.get_cluster_name(cluster_index)

    def get_structured_log_path(self, node_id=0, cluster_index=0):
        return "{}/logs/node-{}.json.log".format(self._get_logs_base_path(cluster_index), node_id)

    def get_node_address(self, node_id=0, cluster_index=0):
        if cluster_index == 0:
            env = self.Env
        else:
            env = self.remote_envs[cluster_index - 1]
        return "localhost:" + str(env.configs["node"][node_id]["rpc_port"])

    def _default_filter(self, event):
        return event.get("user@") != "scheduler"

    def write_log_barrier(self, address, category="Barrier", driver=None, cluster_index=0):
        return write_log_barrier(
            address, category=category, driver=driver,
            cluster_name=self.get_cluster_name(cluster_index))

    def _read_events(self, category, from_barrier=None, to_barrier=None, node_id=0, cluster_index=0,
                     filter=lambda _: True):
        # NB. We need to filter out the IO generated by internal cluster processes. For example, scheduler
        # sometimes writes to //sys/scheduler/event_log. Such events are also logged in the data node and
        # may lead to unexpected test failures.
        def real_filter(event):
            return self._default_filter(event) and filter(event)

        return read_structured_log(
            self.get_structured_log_path(node_id, cluster_index), from_barrier, to_barrier,
            category_filter=category, row_filter=real_filter)

    def _wait_for_events(self, category, count, from_barrier=None, node_id=0, cluster_index=0,
                         filter=lambda _: True, check_event_count=True):
        def is_ready():
            to_barrier = self.write_log_barrier(self.get_node_address(node_id, cluster_index), cluster_index=cluster_index)
            events = self._read_events(category, from_barrier, to_barrier, node_id, cluster_index, filter)
            return count <= len(events)

        wait(is_ready)
        to_barrier = self.write_log_barrier(self.get_node_address(node_id, cluster_index), cluster_index=cluster_index)
        events = self._read_events(category, from_barrier, to_barrier, node_id, cluster_index, filter)
        if check_event_count:
            assert count == len(events)
        return events

    def wait_for_raw_events(self, *args, **kwargs):
        return self._wait_for_events("IORaw", *args, **kwargs)

    def wait_for_aggregate_events(self, *args, **kwargs):
        return self._wait_for_events("IOAggregate", *args, **kwargs)

    def wait_for_path_aggr_events(self, *args, **kwargs):
        return self._wait_for_events("IOPathAggr", *args, **kwargs)
